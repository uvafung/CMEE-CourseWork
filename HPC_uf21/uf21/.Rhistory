simu_data[[i]] <- list(list_interval_spp_abun_oct, burn_in_generations, end_com,
interval_burnin_spp_richness, interval_oct, interval_rich,
size, speciation_rate, time_spent, wall_time)
octave_all_simu[[i]] <- simu_data[[i]][[1]] # save all burn-in generations into a list
}
source("uf21_HPC_2021_main.R")
simu_data <- list()
octave_all_simu <- list()
for (i in 1:100){
file <- paste0("../../results/Neutral_cluster_simulation_", i, ".rda")
load(file,.GlobalEnv)
simu_data[[i]] <- list(list_interval_spp_abun_oct, burn_in_generations, end_com,
interval_burnin_spp_richness, interval_oct, interval_rich,
size, speciation_rate, time_spent, wall_time)
octave_all_simu[[i]] <- simu_data[[i]][[1]] # save all burn-in generations into a list
}
###### Community size = 500
octave_com500 <- list() # create a list of octave for community size = 500
octave_sum_com500 = unlist(octave_all_simu[[1]][81]) # convert octaves from list into vectors -- extract simulation 1, octave
total_com500 <- c()
for (a in 1:25){
max_500 <- length(octave_all_simu[[a]]) # total number of generations per simulation
no_gen_postburnin_com500 = max_500 - 82 # number of generations after burn-in
total_com500 <- c(total_com500, no_gen_postburnin_com500) # number of post-burn-in generations per simulation and add them up
for (b in 82:max_500){
octave_sum_com500 = sum_vect(octave_sum_com500, unlist(octave_all_simu[[a]][[b]])) # sum vectors -- # retrieve a-th sequence of octave_all_simu
octave_com500[[a]] = list(octave_sum_com500) # for each simulation, store the sum of each octave per gen
}
}
octave_com500 = octave_com500[1:25]
###### Community size = 1000
octave_com1000 <- list() # create a list of octave for community size = 1000
octave_sum_com1000 = unlist(octave_all_simu[[26]][81]) # simulation 26, octave 81
total_com1000 <- c()
for (a in 26:50){
max_1000 <- length(octave_all_simu[[a]])
no_gen_postburnin_com1000 = max_1000 - 82
total_com1000 <- c(total_com1000, no_gen_postburnin_com1000)
for (b in 82:max_1000){
octave_sum_com1000 = sum_vect(octave_sum_com1000, unlist(octave_all_simu[[a]][[b]]))
octave_com1000[[a]] = list(octave_sum_com1000)
}
}
octave_com1000 = octave_com1000[26:50]
###### Community size = 2500
octave_com2500 <- list() # create a list of octave for community size = 2500
octave_sum_com2500 = unlist(octave_all_simu[[51]][81]) # simulation 51, octave gen 81
total_com2500 <- c()
for (a in 51:75){
max_2500 <- length(octave_all_simu[[a]])
no_gen_postburnin_com2500 = max_2500 - 82
total_com2500 <- c(total_com2500, no_gen_postburnin_com2500)
for (b in 82:max_2500){
octave_sum_com2500 = sum_vect(octave_sum_com2500, unlist(octave_all_simu[[a]][[b]]))
octave_com2500[[a]] = list(octave_sum_com2500)
}
}
octave_com2500 = octave_com2500[51:75]
###### Community size = 5000
octave_com5000 <- list() # create a list of octave for community size = 5000
octave_sum_com5000 = unlist(octave_all_simu[[76]][81]) # simulation 76, octave gen 81
total_com5000 <- c()
for (a in 76:100){
max_5000 <- length(octave_all_simu[[a]])
no_gen_postburnin_com5000 = max_5000 - 82
total_com5000 <- c(total_com5000, no_gen_postburnin_com5000)
for (b in 82:max_5000){
octave_sum_com5000 = sum_vect(octave_sum_com5000, unlist(octave_all_simu[[a]][[b]]))
octave_com5000[[a]] = list(octave_sum_com5000)
}
}
octave_com5000 = octave_com5000[76:100]
############ sum all octaves
final_sum_com500 = unlist(octave_com500[[1]])
final_sum_com1000 = unlist(octave_com1000[[1]])
final_sum_com2500 = unlist(octave_com2500[[1]])
final_sum_com5000 = unlist(octave_com5000[[1]])
for (s in 2:25){
final_sum_com500 = sum_vect(final_sum_com500, unlist(octave_com500[[s]]))
final_sum_com1000 = sum_vect(final_sum_com1000, unlist(octave_com1000[[s]]))
final_sum_com2500 = sum_vect(final_sum_com2500, unlist(octave_com2500[[s]]))
final_sum_com5000 = sum_vect(final_sum_com5000, unlist(octave_com5000[[s]]))
}
vector_com500 = final_sum_com500 / sum(total_com500)
vector_com1000 = final_sum_com1000 / sum(total_com1000)
vector_com2500 = final_sum_com2500 / sum(total_com2500)
vector_com5000 = final_sum_com5000 / sum(total_com5000)
combined_results <- list(vector_com500, vector_com1000, vector_com2500, vector_com5000)
save(combined_results , file = "vector_all_com.rda")
combined_results <- paste0("vector_all_com.rda")
load(combined_results,.GlobalEnv)
return(combined_results)
combined_results
graphics.off() #clear any existing graphs and plot your graph within the R window
load("vector_all_com.rda")
par(mfrow = c(2, 2))
load("vector_all_com.rda")
return("vector_all_com.rda")
###### Plot community size = 500
barplot(unlist(combined_results[[1]]),
cex.main = 0.8,
main = "Equilibrium state in community size = 500",
xlab = "Number of individuals per species", ylab = "Number of species",
names.arg = c("1", "2-3", "4-7", "8-15", "16-31", "32-63", "64-127", "128-255", "256-511"))
###### Plot community size = 1000
barplot(unlist(combined_results[[2]]),
cex.main = 0.8,
main = "Equilibrium state in community size = 1000",
xlab = "Number of individuals per species", ylab = "Number of species",
names.arg = c("1", "2-3", "4-7", "8-15", "16-31", "32-63", "64-127", "128-255", "256-511", "512-1023"))
###### Plot community size = 2500
barplot(unlist(combined_results[[3]]),
cex.main = 0.8,
main = "Equilibrium state in community size = 2500",
xlab = "Number of individuals per species", ylab = "Number of species",
names.arg = c("1", "2-3", "4-7", "8-15", "16-31", "32-63", "64-127", "128-255", "256-511", "512-1023", "1024-2047"))
###### Plot community size = 5000
barplot(unlist(combined_results[[4]]),
cex.main = 0.8,
main = "Equilibrium state in community with size = 5000",
xlab = "Number of individuals per species", ylab = "Number of species",
names.arg = c("1", "2-3", "4-7", "8-15", "16-31", "32-63", "64-127", "128-255", "256-511"))
source("uf21_HPC_2021_main.R")
rm(list=ls()) # good practice in this instance
##################################3
process_cluster_results()
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
plot_cluster_results()
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
source("uf21_HPC_2021_main.R")
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
combined_results
simu_data <- list()
octave_all_simu <- list()
for (i in 1:100){
file <- paste0("../../results/Neutral_cluster_simulation_", i, ".rda")
load(file,.GlobalEnv)
simu_data[[i]] <- list(list_interval_spp_abun_oct, burn_in_generations, end_com,
interval_burnin_spp_richness, interval_oct, interval_rich,
size, speciation_rate, time_spent, wall_time)
octave_all_simu[[i]] <- simu_data[[i]][[1]] # save all burn-in generations into a list
}
###### Community size = 500
octave_com500 <- list() # create a list of octave for community size = 500
octave_sum_com500 = unlist(octave_all_simu[[1]][81]) # convert octaves from list into vectors -- extract simulation 1, octave
total_com500 <- c()
for (a in 1:25){
max_500 <- length(octave_all_simu[[a]]) # total number of generations per simulation
no_gen_postburnin_com500 = max_500 - 82 # number of generations after burn-in
total_com500 <- c(total_com500, no_gen_postburnin_com500) # number of post-burn-in generations per simulation and add them up
for (b in 82:max_500){
octave_sum_com500 = sum_vect(octave_sum_com500, unlist(octave_all_simu[[a]][[b]])) # sum vectors -- # retrieve a-th sequence of octave_all_simu
octave_com500[[a]] = list(octave_sum_com500) # for each simulation, store the sum of each octave per gen
}
}
octave_com500 = octave_com500[1:25]
###### Community size = 1000
octave_com1000 <- list() # create a list of octave for community size = 1000
octave_sum_com1000 = unlist(octave_all_simu[[26]][81]) # simulation 26, octave 81
total_com1000 <- c()
for (a in 26:50){
max_1000 <- length(octave_all_simu[[a]])
no_gen_postburnin_com1000 = max_1000 - 82
total_com1000 <- c(total_com1000, no_gen_postburnin_com1000)
for (b in 82:max_1000){
octave_sum_com1000 = sum_vect(octave_sum_com1000, unlist(octave_all_simu[[a]][[b]]))
octave_com1000[[a]] = list(octave_sum_com1000)
}
}
octave_com1000 = octave_com1000[26:50]
###### Community size = 2500
octave_com2500 <- list() # create a list of octave for community size = 2500
octave_sum_com2500 = unlist(octave_all_simu[[51]][81]) # simulation 51, octave gen 81
total_com2500 <- c()
for (a in 51:75){
max_2500 <- length(octave_all_simu[[a]])
no_gen_postburnin_com2500 = max_2500 - 82
total_com2500 <- c(total_com2500, no_gen_postburnin_com2500)
for (b in 82:max_2500){
octave_sum_com2500 = sum_vect(octave_sum_com2500, unlist(octave_all_simu[[a]][[b]]))
octave_com2500[[a]] = list(octave_sum_com2500)
}
}
octave_com2500 = octave_com2500[51:75]
###### Community size = 5000 -- burn-in generations changed to 2*com_size = 10000 generations
octave_com5000 <- list() # create a list of octave for community size = 5000
octave_sum_com5000 = unlist(octave_all_simu[[76]][21]) # simulation 76, octave gen 81
total_com5000 <- c()
for (a in 76:100){
max_5000 <- length(octave_all_simu[[a]])
no_gen_postburnin_com5000 = max_5000 - 82
total_com5000 <- c(total_com5000, no_gen_postburnin_com5000)
for (b in 22:max_5000){
octave_sum_com5000 = sum_vect(octave_sum_com5000, unlist(octave_all_simu[[a]][[b]]))
octave_com5000[[a]] = list(octave_sum_com5000)
}
}
octave_com5000 = octave_com5000[76:100]
###### Community size = 5000 -- burn-in generations changed to 2*com_size = 10000 generations
octave_com5000 <- list() # create a list of octave for community size = 5000
octave_sum_com5000 = unlist(octave_all_simu[[76]][21]) # simulation 76, octave gen 81
total_com5000 <- c()
for (a in 76:100){
max_5000 <- length(octave_all_simu[[a]])
no_gen_postburnin_com5000 = max_5000 - 21
total_com5000 <- c(total_com5000, no_gen_postburnin_com5000)
for (b in 22:max_5000){
octave_sum_com5000 = sum_vect(octave_sum_com5000, unlist(octave_all_simu[[a]][[b]]))
octave_com5000[[a]] = list(octave_sum_com5000)
}
}
octave_com5000 = octave_com5000[76:100]
############ sum all octaves
final_sum_com500 = unlist(octave_com500[[1]])
final_sum_com1000 = unlist(octave_com1000[[1]])
final_sum_com2500 = unlist(octave_com2500[[1]])
final_sum_com5000 = unlist(octave_com5000[[1]])
for (s in 2:25){
final_sum_com500 = sum_vect(final_sum_com500, unlist(octave_com500[[s]]))
final_sum_com1000 = sum_vect(final_sum_com1000, unlist(octave_com1000[[s]]))
final_sum_com2500 = sum_vect(final_sum_com2500, unlist(octave_com2500[[s]]))
final_sum_com5000 = sum_vect(final_sum_com5000, unlist(octave_com5000[[s]]))
}
vector_com500 = final_sum_com500 / sum(total_com500)
vector_com1000 = final_sum_com1000 / sum(total_com1000)
vector_com2500 = final_sum_com2500 / sum(total_com2500)
vector_com5000 = final_sum_com5000 / sum(total_com5000)
combined_results <- list(vector_com500, vector_com1000, vector_com2500, vector_com5000) #create your list output here to return
View(combined_results)
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
load("/Users/Uva/Documents/CMEECourseWork/HPC_uf21/results/Neutral_cluster_simulation_1.rda")
View(list_interval_spp_abun_oct)
load("/Users/Uva/Documents/CMEECourseWork/HPC_uf21/results/Neutral_cluster_simulation_93.rda")
View(list_interval_spp_abun_oct)
load("/Users/Uva/Documents/CMEECourseWork/HPC_uf21/results/Neutral_cluster_simulation_42.rda")
View(list_interval_spp_abun_oct)
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
View(list_interval_spp_abun_oct)
source("uf21_HPC_2021_main.R")
question_20()
getwd()
getwd()
getwd()
question_20 <- function(){
datadir = '../../results'
file_names = as.list(dir(path = datadir, pattern = "*.rda"))
file_names = lapply(file_names, function(x) paste0(datadir, x))
tot_generation_count <- list(0, 0, 0, 0)
names(tot_generation_count) <- c(500, 1000, 2500, 5000)
aggregate_octave_lists <- list(list(), list(), list(), list())
names(aggregate_octave_lists) <- c(500, 1000, 2500, 5000)
for (filename in file_names){
load(filename)
burnin_endpoint <- burn_in_generations / interval_oct + 2
# Sum all octaves for the loaded file
octave_sum = c(0, 0)
for (octave in list_interval_spp_abun_oct[burnin_endpoint:length(list_interval_spp_abun_oct)]){
octave_sum <- sum_vect(unlist(octave), octave_sum)  # Unfortunately lapply is not appropriate in this situation
}
# Save summed octaves to list according to size.
aggregate_octave_lists[[toString(size)]] <- c(aggregate_octave_lists[[toString(size)]], list(octave_sum))
# Add length of non-burnin octave list to total size generation counter
tot_generation_count[[toString(size)]] <- tot_generation_count[[toString(size)]] + (length(list_interval_spp_abun_oct) - burnin_endpoint + 1)
}
# Sum all aggregate octave lists for each size
tot_octaves_500 <- c(0, 0)
tot_octaves_1000 <- c(0, 0)
tot_octaves_2500 <- c(0, 0)
tot_octaves_5000 <- c(0, 0)
for (i in rep(1:25)){
tot_octaves_500 <- sum_vect(unlist(aggregate_octave_lists[['500']][i]), tot_octaves_500)
tot_octaves_1000 <- sum_vect(unlist(aggregate_octave_lists[['1000']][i]), tot_octaves_1000)
tot_octaves_2500 <- sum_vect(unlist(aggregate_octave_lists[['2500']][i]), tot_octaves_2500)
tot_octaves_5000 <- sum_vect(unlist(aggregate_octave_lists[['5000']][i]), tot_octaves_5000)
}
# Divide by total generations tested per size
avg_octaves_500 <- tot_octaves_500 / tot_generation_count[['500']]
avg_octaves_1000 <- tot_octaves_1000 / tot_generation_count[['1000']]
avg_octaves_2500 <- tot_octaves_2500 / tot_generation_count[['2500']]
avg_octaves_5000 <- tot_octaves_5000 / tot_generation_count[['5000']]
print("Data Processed")
# Graph in a multi-panel plot
par(mfrow=c(2,2), oma = c(0,0,2,0))
labelvect <- c("1")
for (i in rep(2:max(length(avg_octaves_500), length(avg_octaves_1000),length(avg_octaves_2500), length(avg_octaves_5000)))){
labelvect <- c(labelvect, toString(paste(2^(i-1),"-",(2^i) - 1)))
}
barplot(avg_octaves_500, xlab = "Octave", cex.names = 0.8, ylab = "Average Species Abundance", main = "Size = 500")
barplot(avg_octaves_1000, xlab = "Octave", cex.names = 0.8, ylab = "Average Species Abundance", main = "Size = 1000")
barplot(avg_octaves_2500, xlab = "Octave", cex.names = 0.8, ylab = "Average Species Abundance", main = "Size = 2500")
barplot(avg_octaves_5000, xlab = "Octave", cex.names = 0.8, ylab = "Average Species Abundance", main = "Size = 5000")
title("Speciation rate = 0.006", outer=T)
print("Done")
}
datadir = '../../results'
file_names = as.list(dir(path = datadir, pattern = "*.rda"))
file_names = lapply(file_names, function(x) paste0(datadir, x))
tot_generation_count <- list(0, 0, 0, 0)
names(tot_generation_count) <- c(500, 1000, 2500, 5000)
aggregate_octave_lists <- list(list(), list(), list(), list())
names(aggregate_octave_lists) <- c(500, 1000, 2500, 5000)
for (filename in file_names){
load(filename)
burnin_endpoint <- burn_in_generations / interval_oct + 2
# Sum all octaves for the loaded file
octave_sum = c(0, 0)
for (octave in list_interval_spp_abun_oct[burnin_endpoint:length(list_interval_spp_abun_oct)]){
octave_sum <- sum_vect(unlist(octave), octave_sum)  # Unfortunately lapply is not appropriate in this situation
}
# Save summed octaves to list according to size.
aggregate_octave_lists[[toString(size)]] <- c(aggregate_octave_lists[[toString(size)]], list(octave_sum))
# Add length of non-burnin octave list to total size generation counter
tot_generation_count[[toString(size)]] <- tot_generation_count[[toString(size)]] + (length(list_interval_spp_abun_oct) - burnin_endpoint + 1)
}
datadir = '../../results/'
file_names = as.list(dir(path = datadir, pattern = "*.rda"))
file_names = lapply(file_names, function(x) paste0(datadir, x))
tot_generation_count <- list(0, 0, 0, 0)
names(tot_generation_count) <- c(500, 1000, 2500, 5000)
aggregate_octave_lists <- list(list(), list(), list(), list())
names(aggregate_octave_lists) <- c(500, 1000, 2500, 5000)
for (filename in file_names){
load(filename)
burnin_endpoint <- burn_in_generations / interval_oct + 2
# Sum all octaves for the loaded file
octave_sum = c(0, 0)
for (octave in list_interval_spp_abun_oct[burnin_endpoint:length(list_interval_spp_abun_oct)]){
octave_sum <- sum_vect(unlist(octave), octave_sum)  # Unfortunately lapply is not appropriate in this situation
}
# Save summed octaves to list according to size.
aggregate_octave_lists[[toString(size)]] <- c(aggregate_octave_lists[[toString(size)]], list(octave_sum))
# Add length of non-burnin octave list to total size generation counter
tot_generation_count[[toString(size)]] <- tot_generation_count[[toString(size)]] + (length(list_interval_spp_abun_oct) - burnin_endpoint + 1)
}
# Question 15
sum_vect <- function(x, y) {
a <- length(x)
b <- length(y)
if (a < b){
diff1 <- b - a
for (i in 1:diff1){
x <- append(x, 0)
}
return(x+y)
}
else if (a > b){
diff2 <- a - b
for (i in 1:diff2){
y <- append(y, 0)
}
return(x+y)
}
else{
return(x+y)
}
}
for (filename in file_names){
load(filename)
burnin_endpoint <- burn_in_generations / interval_oct + 2
# Sum all octaves for the loaded file
octave_sum = c(0, 0)
for (octave in list_interval_spp_abun_oct[burnin_endpoint:length(list_interval_spp_abun_oct)]){
octave_sum <- sum_vect(unlist(octave), octave_sum)  # Unfortunately lapply is not appropriate in this situation
}
# Save summed octaves to list according to size.
aggregate_octave_lists[[toString(size)]] <- c(aggregate_octave_lists[[toString(size)]], list(octave_sum))
# Add length of non-burnin octave list to total size generation counter
tot_generation_count[[toString(size)]] <- tot_generation_count[[toString(size)]] + (length(list_interval_spp_abun_oct) - burnin_endpoint + 1)
}
# Sum all aggregate octave lists for each size
tot_octaves_500 <- c(0, 0)
tot_octaves_1000 <- c(0, 0)
tot_octaves_2500 <- c(0, 0)
tot_octaves_5000 <- c(0, 0)
for (i in rep(1:25)){
tot_octaves_500 <- sum_vect(unlist(aggregate_octave_lists[['500']][i]), tot_octaves_500)
tot_octaves_1000 <- sum_vect(unlist(aggregate_octave_lists[['1000']][i]), tot_octaves_1000)
tot_octaves_2500 <- sum_vect(unlist(aggregate_octave_lists[['2500']][i]), tot_octaves_2500)
tot_octaves_5000 <- sum_vect(unlist(aggregate_octave_lists[['5000']][i]), tot_octaves_5000)
}
# Divide by total generations tested per size
avg_octaves_500 <- tot_octaves_500 / tot_generation_count[['500']]
avg_octaves_1000 <- tot_octaves_1000 / tot_generation_count[['1000']]
avg_octaves_2500 <- tot_octaves_2500 / tot_generation_count[['2500']]
avg_octaves_5000 <- tot_octaves_5000 / tot_generation_count[['5000']]
print("Data Processed")
# Graph in a multi-panel plot
par(mfrow=c(2,2), oma = c(0,0,2,0))
labelvect <- c("1")
for (i in rep(2:max(length(avg_octaves_500), length(avg_octaves_1000),length(avg_octaves_2500), length(avg_octaves_5000)))){
labelvect <- c(labelvect, toString(paste(2^(i-1),"-",(2^i) - 1)))
}
barplot(avg_octaves_500, xlab = "Octave", cex.names = 0.8, ylab = "Average Species Abundance", main = "Size = 500")
barplot(avg_octaves_1000, xlab = "Octave", cex.names = 0.8, ylab = "Average Species Abundance", main = "Size = 1000")
barplot(avg_octaves_2500, xlab = "Octave", cex.names = 0.8, ylab = "Average Species Abundance", main = "Size = 2500")
barplot(avg_octaves_5000, xlab = "Octave", cex.names = 0.8, ylab = "Average Species Abundance", main = "Size = 5000")
View(list_interval_spp_abun_oct)
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
question_20()
rm(list=ls()) # good practice in this instance
source("uf21_HPC_2021_main.R")
question_20()
question_20()
tot_generation_count[['5000']]
datadir = '../../results/'
file_names = as.list(dir(path = datadir, pattern = "*.rda"))
file_names = lapply(file_names, function(x) paste0(datadir, x))
tot_generation_count <- list(0, 0, 0, 0)
names(tot_generation_count) <- c(500, 1000, 2500, 5000)
aggregate_octave_lists <- list(list(), list(), list(), list())
names(aggregate_octave_lists) <- c(500, 1000, 2500, 5000)
for (filename in file_names){
load(filename)
burnin_endpoint <- burn_in_generations / interval_oct + 2
# Sum all octaves for the loaded file
octave_sum = c(0, 0)
for (octave in list_interval_spp_abun_oct[burnin_endpoint:length(list_interval_spp_abun_oct)]){
octave_sum <- sum_vect(unlist(octave), octave_sum)  # Unfortunately lapply is not appropriate in this situation
}
# Save summed octaves to list according to size.
aggregate_octave_lists[[toString(size)]] <- c(aggregate_octave_lists[[toString(size)]], list(octave_sum))
# Add length of non-burnin octave list to total size generation counter
tot_generation_count[[toString(size)]] <- tot_generation_count[[toString(size)]] + (length(list_interval_spp_abun_oct) - burnin_endpoint + 1)
}
tot_generation_count[['5000']] <- tot_generation_count[['5000']] + (length(list_interval_spp_abun_oct) - 22 + 1)
View(tot_generation_count)
tot_octaves_5000
for (filename in file_names){
load(filename)
burnin_endpoint <- burn_in_generations / interval_oct + 2
# Sum all octaves for the loaded file
octave_sum = c(0, 0)
for (octave in list_interval_spp_abun_oct[burnin_endpoint:length(list_interval_spp_abun_oct)]){
octave_sum <- sum_vect(unlist(octave), octave_sum)  # Unfortunately lapply is not appropriate in this situation
}
# Save summed octaves to list according to size.
aggregate_octave_lists[[toString(size)]] <- c(aggregate_octave_lists[[toString(size)]], list(octave_sum))
# Add length of non-burnin octave list to total size generation counter
tot_generation_count[[toString(size)]] <- tot_generation_count[[toString(size)]] + (length(list_interval_spp_abun_oct) - burnin_endpoint + 1)
}
tot_generation_count[['5000']] <- tot_generation_count[['5000']] + (length(list_interval_spp_abun_oct) - 22 + 1)
# Sum all aggregate octave lists for each size
tot_octaves_500 <- c(0, 0)
tot_octaves_1000 <- c(0, 0)
tot_octaves_2500 <- c(0, 0)
tot_octaves_5000 <- c(0, 0)
for (i in rep(1:25)){
tot_octaves_500 <- sum_vect(unlist(aggregate_octave_lists[['500']][i]), tot_octaves_500)
tot_octaves_1000 <- sum_vect(unlist(aggregate_octave_lists[['1000']][i]), tot_octaves_1000)
tot_octaves_2500 <- sum_vect(unlist(aggregate_octave_lists[['2500']][i]), tot_octaves_2500)
tot_octaves_5000 <- sum_vect(unlist(aggregate_octave_lists[['5000']][i]), tot_octaves_5000)
}
# Divide by total generations tested per size
avg_octaves_500 <- tot_octaves_500 / tot_generation_count[['500']]
avg_octaves_1000 <- tot_octaves_1000 / tot_generation_count[['1000']]
avg_octaves_2500 <- tot_octaves_2500 / tot_generation_count[['2500']]
avg_octaves_5000 <- tot_octaves_5000 / tot_generation_count[['5000']]
source("uf21_HPC_2021_main.R")
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
rm(list=ls()) # good practice in this instance
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
rm(list=ls()) # good practice in this instance
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
rm(list=ls()) # good practice in this instance
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
rm(list=ls()) # good practice in this instance
source("uf21_HPC_2021_main.R")
##################################3
process_cluster_results()
plot_cluster_results()
